#!/bin/bash

# Final working test script for local Llama model
set -e

echo "ðŸ§ª Final Llama Model Test"
echo "========================="

# Check if Ollama is running
echo "ðŸ” Checking Ollama service..."
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âŒ Ollama is not running"
    exit 1
fi
echo "âœ… Ollama is running"

# List available models
echo ""
echo "ðŸ“‹ Available models:"
models=$(curl -s http://localhost:11434/api/tags | jq -r '.models[] | "   â€¢ \(.name) (\(.size | . / 1024 / 1024 / 1024 | floor)GB)"' 2>/dev/null || echo "   â€¢ Unable to list models")
echo "$models"

# Test 1: Simple greeting
echo ""
echo "ðŸ§ª Test 1: Simple greeting..."
response1=$(timeout 30 curl -s -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama3.2:latest", "prompt": "Hello", "stream": false, "options": {"num_predict": 20}}' 2>/dev/null || echo "{}")

content1=$(echo "$response1" | jq -r '.response' 2>/dev/null || echo "Failed")
if [ "$content1" != "null" ] && [ -n "$content1" ] && [ "$content1" != "Failed" ]; then
    echo "âœ… Simple greeting: $content1"
else
    echo "âŒ Simple greeting failed"
    exit 1
fi

# Test 2: Short code generation
echo ""
echo "ðŸ§ª Test 2: Code generation..."
response2=$(timeout 45 curl -s -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama3.2:latest", "prompt": "Create a C# class with Name property", "stream": false, "options": {"num_predict": 150}}' 2>/dev/null || echo "{}")

content2=$(echo "$response2" | jq -r '.response' 2>/dev/null || echo "Failed")
if [ "$content2" != "null" ] && [ -n "$content2" ] && [ "$content2" != "Failed" ]; then
    echo "âœ… Code generation successful!"
    echo ""
    echo "ðŸ“„ Generated code:"
    echo "=================="
    echo "$content2"
    echo "=================="
else
    echo "âŒ Code generation failed"
    exit 1
fi

# Test 3: Very short Customer entity
echo ""
echo "ðŸ§ª Test 3: Customer entity (short)..."
response3=$(timeout 45 curl -s -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama3.2:latest", "prompt": "C# Customer class with Id and Name", "stream": false, "options": {"num_predict": 100}}' 2>/dev/null || echo "{}")

content3=$(echo "$response3" | jq -r '.response' 2>/dev/null || echo "Failed")
if [ "$content3" != "null" ] && [ -n "$content3" ] && [ "$content3" != "Failed" ]; then
    echo "âœ… Customer entity generation successful!"
    echo ""
    echo "ðŸ“„ Generated Customer class:"
    echo "============================"
    echo "$content3"
    echo "============================"
else
    echo "âŒ Customer entity generation failed"
    exit 1
fi

# Performance test
echo ""
echo "â±ï¸  Performance test..."
start_time=$(date +%s)

perf_response=$(timeout 30 curl -s -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama3.2:latest", "prompt": "Hello world in C#", "stream": false, "options": {"num_predict": 50}}' 2>/dev/null || echo "{}")

end_time=$(date +%s)
duration=$((end_time - start_time))

echo "âœ… Performance test completed in ${duration} seconds"

# Summary
echo ""
echo "ðŸŽ‰ Local Llama Model Test Summary"
echo "================================="
echo "âœ… Ollama service: Running"
echo "âœ… Text generation: Working"
echo "âœ… Code generation: Working"
echo "âœ… Customer entity generation: Working"
echo "âœ… Performance: ${duration}s response time"
echo ""
echo "ðŸš€ Your local Llama model is ready for the Feature Factory!"
echo ""
echo "ðŸ’¡ Note: For longer prompts, the model may take more time to respond."
echo "   The Feature Factory will handle this with proper timeouts and retries."
echo ""
echo "Next steps:"
echo "  1. Run: ./demo-feature-factory-local.sh"
echo "  2. Or test with: dotnet run --project src/Nexo.CLI -- feature generate --description 'Create a Customer management system' --use-local-models"
